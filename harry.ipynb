{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "source": [
    "# Read all the needed datasets\n",
    "dataset들 읽고 합치기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Character                                           Sentence\n",
       "0     Dumbledore  I should've known that you would be here, Prof...\n",
       "1     McGonagall                Good evening, Professor Dumbledore.\n",
       "2     McGonagall                        Are the rumors true, Albus?\n",
       "3     Dumbledore                          I'm afraid so, professor.\n",
       "4     Dumbledore                              The good and the bad.\n",
       "...          ...                                                ...\n",
       "4920    HERMIONE                             How fast is it, Harry?\n",
       "4921       HARRY                                             Lumos.\n",
       "4922       HARRY          I solemnly swear that I am up to no good.\n",
       "4923       HARRY                                  Mischief managed.\n",
       "4924       HARRY                                               Nox.\n",
       "\n",
       "[4925 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Character</th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dumbledore</td>\n      <td>I should've known that you would be here, Prof...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>McGonagall</td>\n      <td>Good evening, Professor Dumbledore.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>McGonagall</td>\n      <td>Are the rumors true, Albus?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dumbledore</td>\n      <td>I'm afraid so, professor.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dumbledore</td>\n      <td>The good and the bad.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4920</th>\n      <td>HERMIONE</td>\n      <td>How fast is it, Harry?</td>\n    </tr>\n    <tr>\n      <th>4921</th>\n      <td>HARRY</td>\n      <td>Lumos.</td>\n    </tr>\n    <tr>\n      <th>4922</th>\n      <td>HARRY</td>\n      <td>I solemnly swear that I am up to no good.</td>\n    </tr>\n    <tr>\n      <th>4923</th>\n      <td>HARRY</td>\n      <td>Mischief managed.</td>\n    </tr>\n    <tr>\n      <th>4924</th>\n      <td>HARRY</td>\n      <td>Nox.</td>\n    </tr>\n  </tbody>\n</table>\n<p>4925 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "input_file = r'.\\data' # csv파일들이 있는 디렉토리 위치\n",
    "output_file = r'.\\data\\Harry Potter.csv' # 병합하고 저장하려는 파일명\n",
    "\n",
    "allFile_list = glob.glob(os.path.join(input_file, 'Harry Potter *')) # glob함수로 sales_로 시작하는 파일들을 모은다\n",
    "allData = [] # 읽어 들인 csv파일 내용을 저장할 빈 리스트를 하나 만든다\n",
    "for file in allFile_list:\n",
    "    df = pd.read_csv(file,sep=';', encoding='iso-8859-1') # for구문으로 csv파일들을 읽어 들인다\n",
    "    df.columns = ['Character','Sentence'] # index를 \n",
    "    allData.append(df) # 빈 리스트에 읽어 들인 내용을 추가한다\n",
    "dataCombine = pd.concat(allData, axis=0, ignore_index=True) # 리스트의 내용을 수직으로 병합. ignore_index=True는 인데스 값이 기존 순서를 무시하고 순서대로 정렬되도록 한다.\n",
    "dataCombine.to_csv(output_file, index=False) # to_csv함수로 저장한다. 인데스를 빼려면 False로 설정\n",
    "\n",
    "harry=pd.read_csv('./data/Harry Potter.csv')\n",
    "harry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Character  Sentence\n",
       "Character                           \n",
       "\\nSTAN SHUNPIKE          1         1\n",
       "Fat Lady                 1         1\n",
       "Flint                    1         1\n",
       "Flint                    1         1\n",
       "George                   1         1\n",
       "...                    ...       ...\n",
       "HAGRID                   1       175\n",
       "LUPIN                    1       205\n",
       "HERMIONE                 1       302\n",
       "RON                      1       306\n",
       "HARRY                    1       624\n",
       "\n",
       "[187 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Character</th>\n      <th>Sentence</th>\n    </tr>\n    <tr>\n      <th>Character</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>\\nSTAN SHUNPIKE</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Fat Lady</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Flint</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Flint</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>George</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>HAGRID</th>\n      <td>1</td>\n      <td>175</td>\n    </tr>\n    <tr>\n      <th>LUPIN</th>\n      <td>1</td>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>HERMIONE</th>\n      <td>1</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>RON</th>\n      <td>1</td>\n      <td>306</td>\n    </tr>\n    <tr>\n      <th>HARRY</th>\n      <td>1</td>\n      <td>624</td>\n    </tr>\n  </tbody>\n</table>\n<p>187 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "harry.groupby('Character').nunique().sort_values(by='Sentence',ascending='False')"
   ]
  },
  {
   "source": [
    "# Stemming\n",
    "morph analysis 기법."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                               Sentence\n",
      "0                                              Sentence\n",
      "1     I should've known that you would be here, Prof...\n",
      "2                   Good evening, Professor Dumbledore.\n",
      "3                           Are the rumors true, Albus?\n",
      "4                             I'm afraid so, professor.\n",
      "...                                                 ...\n",
      "4923                             How fast is it, Harry?\n",
      "4924                                             Lumos.\n",
      "4925          I solemnly swear that I am up to no good.\n",
      "4926                                  Mischief managed.\n",
      "4927                                               Nox.\n",
      "\n",
      "[4928 rows x 1 columns]\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:\\Users\\kimdu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     D:\\Users\\kimdu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Character'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Character'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a92c20d65fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mharry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrainPotter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mharry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Character'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^a-zA-Z ]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainPotter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Character'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "harry=pd.read_csv('./data/Harry Potter.csv')\n",
    "print(harry)\n",
    "\n",
    "trainPotter = harry['Character'].str.replace('[^a-zA-Z ]', '')\n",
    "print(trainPotter)\n",
    "\n",
    "tokenData = nltk.word_tokenize(str(trainPotter))\n",
    "print(tokenData)\n",
    "\n",
    "stemData=[]\n",
    "for w in tokenData:\n",
    "    tempData=[]\n",
    "    tempData=ps.stem(w)\n",
    "    stemData.append(tempData)\n",
    "    \n",
    "print(stemData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 정제하기\n",
    "\n",
    "harry1['Sentence'] = harry1['Sentence'].str.replace('[^a-zA-Z ]', '') #알파벳과 공백을 제외하고 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}