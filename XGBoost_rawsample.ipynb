{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request"
   ]
  },
  {
   "source": [
    "# MBTI 별 posting 모으기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      posts\n",
       "type       \n",
       "ENFJ    190\n",
       "ENFP    675\n",
       "ENTJ    231\n",
       "ENTP    685\n",
       "ESFJ     42\n",
       "ESFP     48\n",
       "ESTJ     39\n",
       "ESTP     89\n",
       "INFJ   1470\n",
       "INFP   1832\n",
       "INTJ   1091\n",
       "INTP   1304\n",
       "ISFJ    166\n",
       "ISFP    271\n",
       "ISTJ    205\n",
       "ISTP    337"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posts</th>\n    </tr>\n    <tr>\n      <th>type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ENFJ</th>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>ENFP</th>\n      <td>675</td>\n    </tr>\n    <tr>\n      <th>ENTJ</th>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>ENTP</th>\n      <td>685</td>\n    </tr>\n    <tr>\n      <th>ESFJ</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>ESFP</th>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>ESTJ</th>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>ESTP</th>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>INFJ</th>\n      <td>1470</td>\n    </tr>\n    <tr>\n      <th>INFP</th>\n      <td>1832</td>\n    </tr>\n    <tr>\n      <th>INTJ</th>\n      <td>1091</td>\n    </tr>\n    <tr>\n      <th>INTP</th>\n      <td>1304</td>\n    </tr>\n    <tr>\n      <th>ISFJ</th>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>ISFP</th>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>ISTJ</th>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>ISTP</th>\n      <td>337</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "mbti=pd.read_csv('./data/mbti_1.csv')\n",
    "\n",
    "types = mbti.groupby('type').count()\n",
    "\n",
    "output_file = '.\\data\\\\training\\\\mbti.csv' # raw string이 아니라 '\\'를 쓰려면 \\\\라고 해야 함\n",
    "allData = []\n",
    "\n",
    "for type in types.index:\n",
    "    condition = mbti['type'] == type # condition: mbti['type']가 topfive의 원소인 type 같을 bool 조건\n",
    "    ownsentence = mbti[condition]  # ownsentence: condition에 맞는 row만 filtering한 dataframe\n",
    "    allData.append(ownsentence)\n",
    "dataCombine = pd.concat(allData, axis=0, ignore_index=True)\n",
    "dataCombine.to_csv(output_file, index=False)\n",
    "\n",
    "types\n",
    "\n",
    "    #input_file = r'.\\data\\training'\n",
    "    #allFile_list = glob.glob(os.path.join(input_file, 'mbti_*'))\n",
    "    #for file in allFile_list:\n",
    "    #    csv = pd.read_csv(file,sep=';', encoding='iso-8859-1') # for구문으로 csv파일들을 읽어 들인다\n",
    "    #    cleanMbti = csv['posts'].str.replace('[^A-Za-z\\s]+', '')"
   ]
  },
  {
   "source": [
    "# Resampling (Undersampling and Oversampling)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Tokenize and Stemming\n",
    "morph analysis 기법."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gc\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mbti= dataCombine\n",
    "X_data = mbti['posts']\n",
    "y_data = mbti['type']\n",
    "\n",
    "normalized_text = []\n",
    "for sentence in X_data.tolist():\n",
    "    clean_sentence = re.sub('[^A-Za-z\\s]+', '',sentence.lower())    # posts 데이터 정규화()\n",
    "    normalized_text.append(clean_sentence)\n",
    "mbti.posts = normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21957"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "\n",
    "# print(\"stopwords 제거 시작\")\n",
    "stopwords = ['http*']\n",
    "#print(\"stopwords 제거 완료\")\n",
    "\n",
    "stemData=[] # stemmed X_data: mbti['posts']\n",
    "tokenizedData=[]    # tokenized X_data\n",
    "for sentence in mbti['posts']:\n",
    "    tokenData = nltk.word_tokenize(sentence)\n",
    "    tempData = []   # 개별 post\n",
    "    for word in tokenData:\n",
    "        tempData.append(ps.stem(word))\n",
    "        #tempData = [word for word in tempData if not word in stopwords] # 불용어 제거\n",
    "    tokenizedData.append(tokenData)\n",
    "    stemData.append(tempData)\n",
    "#print(stemData[0])\n",
    "\n",
    "#'list' object has no attribute 'lower' 문제 발생\n",
    "# 2차원 리스트인 stemData를 1차원 리스트로\n",
    "#flat_stem = [item for sublist in stemData for item in sublist]\n",
    "\n",
    "del [[mbti]]\n",
    "gc.collect()"
   ]
  },
  {
   "source": [
    "# Data 확인\n",
    "실제 data와 stemmed Data의 양상이 일치하는지 확인. 확인 결과 한 post의 길이가 지나치게 적은 곳이 있었지만, 결과에 유의미하게 부정적인 영향을 미치지 않는다고 판단해서 정제하지 않기로 했다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagoftoken = tokenizedData.flatten()\n",
    "# bagofstemmed = stemData.flatten()\n",
    "\n",
    "print('post의 최대 길이(단어 수) :{}'.format(max(len(l) for l in stemData)))\n",
    "print('post의 최소 길이 :{}'.format(min(len(l) for l in stemData)))\n",
    "print('post의 평균 길이 :{}'.format(sum(map(len, stemData))/len(stemData)))\n",
    "print('post의 전체 길이 :{}'.format(sum(map(len, stemData))))\n",
    "print('post의 갯수: {}'.format(len(stemData)))\n",
    "print('첫 post의 단어 개수:{}'.format(len(stemData[0])))\n",
    "\n",
    "plt.hist([len(s) for s in stemData], bins=50)\n",
    "plt.xlabel('length of stemmed posts')\n",
    "plt.ylabel('number of stemmed posts')\n",
    "plt.show()\n",
    "\n",
    "plt.hist([len(s) for s in tokenizedData], bins=50)\n",
    "plt.xlabel('length of raw posts')\n",
    "plt.ylabel('number of raw posts')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Vectorization(tfidf)\n",
    "padding 과정이 따로 필요하지 않은 output이 나와서 padding 생략"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.15619188 0.         0.         ... 0.         0.         0.        ]\n [0.22128246 0.04019078 0.         ... 0.         0.         0.        ]\n [0.14145265 0.         0.         ... 0.         0.         0.        ]\n ...\n [0.18796687 0.         0.         ... 0.         0.         0.        ]\n [0.19099817 0.         0.         ... 0.         0.         0.        ]\n [0.13217717 0.         0.         ... 0.         0.         0.        ]]\n0       ENFJ\n1       ENFJ\n2       ENFJ\n3       ENFJ\n4       ENFJ\n        ... \n8670    ISTP\n8671    ISTP\n8672    ISTP\n8673    ISTP\n8674    ISTP\nName: type, Length: 8675, dtype: object\n['ENFJ' 'ENFJ' 'ENFJ' ... 'ISTP' 'ISTP' 'ISTP']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'tf = TfidfVectorizer().fit(stemData)\\nprint(tf.transform(stemData).toarray())\\nprint(tf.vocabulary_)\\n#print(vector.vocabulary_)'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf=TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None\n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(stemData).toarray()\n",
    "print(X)\n",
    "\n",
    "print(y_data)\n",
    "y = np.array(y_data)\n",
    "print(y)\n",
    "\n",
    "# le = LabelEncoder() # string인 'type' label을 int로 바꿔준다 (input: array)\n",
    "# y = le.fit_transform(y).reshape(-1,1)\n",
    "# y = to_categorical(y)\n",
    "'''tf = TfidfVectorizer().fit(stemData)\n",
    "print(tf.transform(stemData).toarray())\n",
    "print(tf.vocabulary_)\n",
    "#print(vector.vocabulary_)'''"
   ]
  },
  {
   "source": [
    "# Garbage Collection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model building Start\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(\"Model building Start\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=1234)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model building End\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(\"Model building End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['XGBoost_rawsample.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'XGBoost_rawsample.pkl')"
   ]
  },
  {
   "source": [
    "# Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation Start\n0.6496350364963503\n[0.6        0.65306122 0.6875     0.64974619 1.         0.33333333\n 0.66666667 0.4        0.64574899 0.65785381 0.65662651 0.64268585\n 0.67647059 0.59090909 0.66666667 0.68235294]\n[0.36       0.61835749 0.5        0.59813084 0.08333333 0.06666667\n 0.25       0.26086957 0.71205357 0.76909091 0.68125    0.67848101\n 0.43396226 0.45348837 0.39393939 0.64444444]\n[0.45       0.63523573 0.57894737 0.62287105 0.15384615 0.11111111\n 0.36363636 0.31578947 0.67728238 0.70913663 0.66871166 0.66009852\n 0.52873563 0.51315789 0.4952381  0.66285714]\nEvaluation END\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "print(\"Evaluation Start\")\n",
    "# labels과 guesses\n",
    "labels = preds\n",
    "guesses = y_test\n",
    "\n",
    "print(accuracy_score(labels, guesses))\n",
    "print(recall_score(labels, guesses, average=None))\n",
    "print(precision_score(labels, guesses, average=None))\n",
    "print(f1_score(labels, guesses, average=None))\n",
    "\n",
    "print(\"Evaluation END\")\n",
    "# https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}