{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request"
   ]
  },
  {
   "source": [
    "# MBTI 별 posting 모으기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti=pd.read_csv('./data/mbti_1.csv')\n",
    "\n",
    "types = mbti.groupby('type').count()\n",
    "types.index\n",
    "\n",
    "output_file = '.\\data\\\\training\\\\mbti.csv' # raw string이 아니라 '\\'를 쓰려면 \\\\라고 해야 함\n",
    "allData = []\n",
    "\n",
    "for type in types.index:\n",
    "    condition = mbti['type'] == type # condition: mbti['type']가 topfive의 원소인 type 같을 bool 조건\n",
    "    ownsentence = mbti[condition]  # ownsentence: condition에 맞는 row만 filtering한 dataframe\n",
    "    allData.append(ownsentence)\n",
    "dataCombine = pd.concat(allData, axis=0, ignore_index=True)\n",
    "dataCombine.to_csv(output_file, index=False)\n",
    "\n",
    "    #input_file = r'.\\data\\training'\n",
    "    #allFile_list = glob.glob(os.path.join(input_file, 'mbti_*'))\n",
    "    #for file in allFile_list:\n",
    "    #    csv = pd.read_csv(file,sep=';', encoding='iso-8859-1') # for구문으로 csv파일들을 읽어 들인다\n",
    "    #    cleanMbti = csv['posts'].str.replace('[^A-Za-z\\s]+', '')"
   ]
  },
  {
   "source": [
    "# Stemming\n",
    "morph analysis 기법."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:\\Users\\kimdu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     D:\\Users\\kimdu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "['0', 'httpswwwyoutubecomwatchvplaaikvhvz', 'oI', 'went', 'th', '...', '1', 'httpswwwyoutubecomwatchvawgfyslpw', 'I', 'do', 'stuff', '...', '2', 'that', 'sound', 'like', 'a', 'beauti', 'relationship', 'alr', '...', '3', 'ive', 'alway', 'thought', 'of', 'toni', 'stark', 'as', 'more', 'of', 'an', '...', '4', 'abil', 'TO', 'transform', 'form', 'of', 'a', 'bucket', 'of', 'wate', '...', '...', '8670', 'I', 'got', 'istp', 'My', 'final', 'word', 'wa', 'bum', 'so', 'I', 'guess', 'th', '...', '8671', 'i', 'dont', 'mind', 'if', 'ppl', 'do', 'sleep', 'whit', 'sock', 'when', 'i', '...', '8672', 'I', 'wa', 'in', 'the', 'navi', 'for', 'year', 'I', 'hate', 'everi', 'mi', '...', '8673', 'To', 'me', 'to', 'be', 'sensit', 'is', 'to', 'be', 'human', 'I', 'have', 'a', '...', '8674', 'be', 'alon', 'be', 'insensit', 'over', 'think', 'o', '...', 'name', ':', 'post', ',', 'length', ':', '8675', ',', 'dtype', ':', 'object']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "mbti= dataCombine\n",
    "\n",
    "cleanMbti = mbti['posts'].str.replace('[^A-Za-z\\s]+', '')\n",
    "tokenData = nltk.word_tokenize(str(cleanMbti))\n",
    "\n",
    "\n",
    "stemMbtiData=[]\n",
    "for w in tokenData:\n",
    "    tempData=[]\n",
    "    tempData=ps.stem(w)\n",
    "    stemMbtiData.append(tempData)\n",
    "\n",
    "print(stemMbtiData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}