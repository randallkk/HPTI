{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# (MBTI 별 Data 모으기: 생략) MBTI file 불러오기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti=pd.read_csv('.\\data\\\\training\\\\mbti.csv')"
   ]
  },
  {
   "source": [
    "# UnderSampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'ENFJ': 39,\n",
       "         'ENFP': 39,\n",
       "         'ENTJ': 39,\n",
       "         'ENTP': 39,\n",
       "         'ESFJ': 39,\n",
       "         'ESFP': 39,\n",
       "         'ESTJ': 39,\n",
       "         'ESTP': 39,\n",
       "         'INFJ': 39,\n",
       "         'INFP': 39,\n",
       "         'INTJ': 39,\n",
       "         'INTP': 39,\n",
       "         'ISFJ': 39,\n",
       "         'ISFP': 39,\n",
       "         'ISTJ': 39,\n",
       "         'ISTP': 39})"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X_data = mbti['posts']\n",
    "X = X_data.values.reshape(-1, 1)\n",
    "\n",
    "y_data = mbti['type']\n",
    "y = y_data.values.reshape(-1, 1)\n",
    "\n",
    "X_resampled, y_resampled = RandomUnderSampler(random_state=0).fit_sample(X, y)\n",
    "#format(Counter(y_resampled))\n",
    "X_resampled #ndarray\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "source": [
    "# tokenize and stemming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "normalize 시작\nnormalize 완료\n"
     ]
    }
   ],
   "source": [
    "X_data = X_resampled.ravel()\n",
    "y_data = y_resampled\n",
    "\n",
    "\n",
    "print(\"normalize 시작\")\n",
    "normalized_text = []\n",
    "for sentence in X_data: #for sentence in X_data.ravel()\n",
    "    rm_urls = re.sub(r'http[s]?://\\S+', '', sentence)\n",
    "    clean_sentence = re.sub('[^A-Za-z\\s]+', '', rm_urls.lower())\n",
    "    normalized_text.append(clean_sentence)\n",
    "X_data = normalized_text\n",
    "print(\"normalize 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gc\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "stemming 시작\n",
      "stemming 완료\n",
      "['want', 'know', 'feel', 'intp', 'actual', 'intp', 'idea', 'intp', 'havent', 'met', 'anyten', 'million', 'hug', 'mani', 'amaz', 'convers', 'held', 'absenc', 'vow', 'never', 'leav', 'realli', 'lot', 'written', 'recent', 'terriblyfacebook', 'way', 'emphas', 'other', 'error', 'cognit', 'becom', 'obviou', 'lead', 'wonder', 'im', 'friend', 'mani', 'peopl', 'rememb', 'peopl', 'moremmmmhm', 'ive', 'wonder', 'late', 'ei', 'think', 'definit', 'much', 'needwant', 'compani', 'around', 'regardless', 'time', 'togeth', 'spenthahah', 'love', 'think', 'that', 'go', 'topic', 'excel', 'convers', 'thank', 'particip', 'indulg', 'interest', 'enlighteningsomeon', 'creat', 'chitchat', 'thread', 'enfj', 'forum', 'enfj', 'vigilantli', 'await', 'type', 'wander', 'start', 'conversationswa', 'enfp', 'ive', 'caught', 'mani', 'text', 'look', 'around', 'shini', 'object', 'give', 'midsyl', 'mm', 'hmm', 'alway', 'mani', 'andi', 'tire', 'extravert', 'energysap', 'sentiment', 'arent', 'batshit', 'loud', 'outgo', 'even', 'dryon', 'topic', 'guy', 'find', 'get', 'better', 'extrovert', 'onlinealso', 'iamken', 'one', 'yall', 'sure', 'type', 'lot', 'think', 'introvert', 'thing', 'rather', 'fi', 'thing', 'though', 'intp', 'fe', 'way', 'intp', 'infp', 'actual', 'haveb', 'contrari', 'think', 'initi', 'interact', 'begin', 'selffocu', 'realli', 'depend', 'im', 'feel', 'though', 'im', 'insecur', 'kind', 'day', 'someon', 'isth', 'hand', 'yesi', 'attribut', 'credibl', 'advic', 'follow', 'experi', 'date', 'hous', 'keep', 'intp', 'fed', 'littl', 'longer', 'two', 'year', 'find', 'intp', 'rareyour', 'abil', 'candid', 'refresh', 'thing', 'unhealthi', 'usi', 'clarifi', 'rambl', 'lie', 'mean', 'less', 'valid', 'next', 'less', 'reliabl', 'misconstru', 'intp', 'differ', 'other', 'mean', 'vastli', 'aeffi', 'iamtp', 'interest', 'thought', 'intp', 'behav', 'like', 'infp', 'think', 'ive', 'seen', 'happen', 'intp', 'current', 'think', 'intp', 'differ', 'fromth', 'cognit', 'function', 'test', 'differ', 'mbti', 'magicwhoa', 'much', 'happen', 'day', 'want', 'take', 'opportun', 'make', 'observ', 'page', 'sinc', 'feel', 'like', 'miss', 'thismight', 'enneagram', 'type', 'thing', 'relat', 'im', 'enfj', 'think', 'ask', 'make', 'enfj', 'happi', 'peopl', 'make', 'us', 'happyhistoir', 'soo', 'unfold', 'make', 'move', 'yet', 'peopl', 'ha', 'guarante', 'like', 'quieter', 'usual', 'also', 'dont', 'confus', 'introvers', 'lack', 'confid', 'samei', 'think', 'odd', 'behavior', 'enfj', 'behavior', 'your', 'describ', 'sound', 'introvert', 'mayb', 'he', 'intimidatedi', 'cant', 'speak', 'everyon', 'els', 'person', 'experi', 'alway', 'think', 'even', 'someth', 'overthink', 'even', 'person', 'interact', 'seem', 'absorb', 'convers', 'butno', 'absolut', 'wouldnt', 'overwhelm', 'think', 'person', 'explain', 'relat', 'would', 'even', 'thing', 'way', 'plan', 'know', 'mean', 'youjust', 'got', 'thing', 'left', 'eye', 'still', 'hurt', 'rawrwel', 'im', 'go', 'honest', 'someon', 'walk', 'like', 'cat', 'fall', 'fit', 'rage', 'burst', 'laugh', 'second', 'later', 'sound', 'aw', 'immatur', 'unstabl', 'possiblyr', 'someon', 'field', 'true', 'constantli', 'odd', 'buy', 'ive', 'ask', 'other', 'forum', 'dont', 'think', 'mani', 'peopl', 'inbait', 'approv', 'would', 'bug', 'answer', 'would', 'cant', 'make', 'stop', 'period', 'that', 'itheheheheh', 'idk', 'id', 'say', 'im', 'pretti', 'organ', 'schedul', 'that', 'natur', 'j', 'said', 'dont', 'think', 'anyth', 'sex', 'drive', 'like', 'lofti', 'said', 'probablyidk', 'well', 'sex', 'food', 'correl', 'person', 'type', 'mayb', 'thatd', 'interest', 'thing', 'researchi', 'also', 'disagre', 'think', 'simpli', 'obviou', 'extravert', 'spastic', 'obnoxi', 'natur', 'extravers', 'mere', 'feel', 'divulg', 'easili', 'process', 'externallyhahaha', 'someon', 'sound', 'excit', 'forgot', 'mention', 'poni', 'also', 'might', 'want', 'chang', 'word', 'bit', 'screw', 'need', 'protect', 'im', 'sorri', 'blanket', 'statement', 'peopl', 'run', 'gamut', 'e', 'black', 'white', 'youll', 'find', 'plenti', 'extravert', 'person', 'prefer', 'spend', 'time', 'home', 'one', 'twohahaha', 'connoisseur', 'reject', 'play', 'dumb', 'alway', 'goto', 'women', 'tend', 'get', 'shove', 'face', 'eventu', 'total', 'possibl', 'id', 'send', 'pictur', 'might', 'awkward', 'poor', 'intp', 'intens', 'stori', 'cant', 'wait', 'see', 'happen', 'hope', 'run', 'keep', 'mind', 'infpenfj', 'interact', 'weird', 'go', 'head', 'mightkittydian', 'true', 'said', 'pretti', 'much', 'demand', 'introduc', 'two', 'year', 'ago', 'nbd', 'wont', 'chang', 'opinion', 'thing', 'realiz', 'howdo', 'tell', 'im', 'intrigu', 'happen', 'intp', 'fire', 'readythi', 'ador', 'perhap', 'also', 'conflict', 'two', 'interact', 'like', 'typic', 'curiou', 'shi', 'approach', 'someon', 'dont', 'expecti', 'cant', 'speak', 'everyon', 'ill', 'speak', 'sign', 'enfj', 'give', 'away', 'attract', 'your', 'attract', 'depend', 'much', 'inform', 'aboutif', 'read', 'link', 'youll', 'see', 'extinguish', 'partner', 'infp', 'actual', 'enfp', 'love', 'japanes', 'literatur', 'someth', 'look', 'mayb', 'share', 'favorit', 'book', 'note', 'one', 'favorit', 'novella', 'banana', 'yoshimotosometim', 'there', 'effect', 'wholesom', 'isnt', 'intrigu', 'challeng', 'enough', 'factor', 'young', 'boy', 'chang', 'friend', 'get', 'older', 'tell', 'absolut', 'toim', 'go', 'say', 'word', 'caution', 'onlin', 'survey', 'least', 'reliabl', 'method', 'take', 'poll', 'two', 'big', 'reason', 'dont', 'know', 'person', 'answer', 'question', 'theythi', 'terrifi', 'thank', 'share', 'she', 'beauti']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "\n",
    "# print(\"stopwords 제거 시작\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#print(\"stopwords 제거 완료\")\n",
    "\n",
    "print(\"stemming 시작\")\n",
    "stemData=[]\n",
    "for sentence in X_data:\n",
    "    tokenData = nltk.word_tokenize(sentence)\n",
    "    tempData = []\n",
    "    for word in tokenData:\n",
    "        if word not in stop_words:\n",
    "            tempData.append(ps.stem(word))\n",
    "    stemData.append(tempData)\n",
    "print(\"stemming 완료\")\n",
    "print(stemData[0])\n",
    "\n",
    "#'list' object has no attribute 'lower' 문제 발생\n",
    "#2차원 리스트인 stemData를 1차원 리스트로\n",
    "#flat_stem = [item for sublist in stemData for item in sublist]\n",
    "del [[mbti]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n [0.05858548 0.         0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]\n ...\n [0.04542902 0.         0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#vectorization (tfidf)\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf=TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None\n",
    ")\n",
    "\n",
    "tfidf.fit(stemData)\n",
    "print(tfidf.transform(stemData).toarray())\n",
    "X = tfidf.transform(stemData).toarray()\n",
    "y = np.array(y_data)\n"
   ]
  },
  {
   "source": [
    "# XGBoost_Undersampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model building Start\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "print(\"Model building Start\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=1234)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model building End\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(\"Model building End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['XGBoost_undersample.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'XGBoost_undersample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation Start\n0.5\n[0.66666667 0.54545455 0.45454545 0.16666667 0.8        0.29411765\n 0.58333333 0.9        0.33333333 0.90909091 0.42857143 0.125\n 0.42857143 0.42857143 0.47368421 0.53846154]\n[0.75       0.46153846 0.625      0.2        0.5        0.45454545\n 0.46666667 0.69230769 0.125      0.76923077 0.33333333 0.1\n 0.6        0.6        0.5        0.63636364]\n[0.70588235 0.5        0.52631579 0.18181818 0.61538462 0.35714286\n 0.51851852 0.7826087  0.18181818 0.83333333 0.375      0.11111111\n 0.5        0.5        0.48648649 0.58333333]\nEvaluation END\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Evaluation Start\")\n",
    "# labels과 guesses\n",
    "labels = preds\n",
    "guesses = y_test\n",
    "\n",
    "print(accuracy_score(labels, guesses))\n",
    "print(recall_score(labels, guesses, average=None))\n",
    "print(precision_score(labels, guesses, average=None))\n",
    "print(f1_score(labels, guesses, average=None))\n",
    "\n",
    "print(\"Evaluation END\")\n",
    "# https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/"
   ]
  }
 ]
}